{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time: 14.10.2021 10:05:23\n",
      "Mitteln\n",
      "duplicating nofaces\n",
      "to_dup: 26950\n",
      "duplicated: 10000\n",
      "duplicated: 20000\n",
      "to_dup: 18910\n",
      "duplicated: 30000\n",
      "duplicated: 40000\n",
      "copied: 10000\n",
      "copied: 20000\n",
      "copied: 30000\n",
      "copied: 40000\n",
      "choosing faces\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "done choosing\n",
      "start copying\n",
      "copied: 10000\n",
      "copied: 20000\n",
      "copied: 30000\n",
      "copied: 40000\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 1] Operation not permitted: 'ausgewaehlt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-693c9319afee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0mnewpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"ausgewaehlt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0mnewpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"duplicated\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 1] Operation not permitted: 'ausgewaehlt'"
     ]
    }
   ],
   "source": [
    "#ADAPT FILES\n",
    "import os\n",
    "from shutil import copyfile\n",
    "import time\n",
    "\n",
    "from random import sample\n",
    "\n",
    "def choice(desired):\n",
    "    files = os.listdir('./train_images_test/1/')\n",
    "    i = 0\n",
    "    for file in sample(files,desired):\n",
    "        #os.remove('/train_images_test/1/'+ file)\n",
    "        newpath = \"ausgewaehlt\"\n",
    "        if not os.path.exists(newpath):\n",
    "            os.makedirs(newpath)\n",
    "        copyfile('./train_images_test/1/' + file, './ausgewaehlt/' + file)\n",
    "        if(i%10000 == 0):\n",
    "            print(i)\n",
    "        i += 1\n",
    "    print(\"done choosing\")\n",
    "\n",
    "def duplicate(desired):\n",
    "    aktuell = 0\n",
    "    files = os.listdir('./train_images_test/0/')\n",
    "    i = aktuell\n",
    "    loop = 0\n",
    "    newpath = \"duplicated\"\n",
    "    if not os.path.exists(newpath):\n",
    "        os.makedirs(newpath)\n",
    "    while (aktuell < desired):\n",
    "        if((desired - aktuell) < aktuell): to_dup = desired - aktuell\n",
    "        else: to_dup = 26950\n",
    "        print(\"to_dup: \" + str(to_dup))\n",
    "        for file in sample(files, to_dup):\n",
    "            copyfile('./train_images_test/0/' + file, './duplicated/' + str(loop) + file)\n",
    "            i += 1\n",
    "            if(i%10000 == 0): print(\"duplicated: \" + str(i))\n",
    "        aktuell += to_dup\n",
    "        loop += 1\n",
    "\n",
    "def auswahl():\n",
    "    newpath = \"01small\"\n",
    "    if not os.path.exists(newpath):\n",
    "        os.makedirs(newpath)\n",
    "    newpath = \"01small/0\"\n",
    "    if not os.path.exists(newpath):\n",
    "        os.makedirs(newpath)\n",
    "    newpath = \"01small/1\"\n",
    "    if not os.path.exists(newpath):\n",
    "        os.makedirs(newpath)\n",
    "\n",
    "    #0_nofaces\n",
    "    files = os.listdir('./train_images_test/0/')\n",
    "    print(\"Copying no faces...\")\n",
    "    for file in files:\n",
    "        copyfile('./train_images_test/0/' + file, './01small/0/' + file)\n",
    "    print(\"Copying done!\")\n",
    "\n",
    "    #1_faces\n",
    "    files = os.listdir('./train_images_test/1/')\n",
    "    choice(26950)\n",
    "    to_move = os.listdir('./ausgewaehlt/')\n",
    "    print('copying files to destination')\n",
    "    i = 0\n",
    "    for file in to_move:\n",
    "        copyfile('./ausgewaehlt/' + file, './01small/1/' + file)\n",
    "        os.remove('./ausgewaehlt/' + file)\n",
    "        i += 1\n",
    "        if(i%10000 == 0): print(\"copied: \" + str(i))\n",
    "\n",
    "\n",
    "def hochrechnen():\n",
    "    print(\"Hochrechnen....\")\n",
    "    newpath = \"02big\"\n",
    "    if not os.path.exists(newpath):\n",
    "        os.makedirs(newpath)\n",
    "    newpath = \"02big/0\"\n",
    "    if not os.path.exists(newpath):\n",
    "        os.makedirs(newpath)\n",
    "    newpath = \"02big/1\"\n",
    "    if not os.path.exists(newpath):\n",
    "        os.makedirs(newpath)\n",
    "\n",
    "    #0nofaces\n",
    "    print(\"duplicating nofaces\")\n",
    "    duplicate(64770)\n",
    "    to_move = os.listdir('./duplicated/')\n",
    "    print(\"Copying files\")\n",
    "    for file in to_move:\n",
    "        copyfile('./duplicated/' + file, './02big/0/' + file)\n",
    "        os.remove(\"./duplicated/\" + file)\n",
    "    \n",
    "    #1faces\n",
    "    print(\"choosing faces\")\n",
    "    files = os.listdir('./train_images_test/1/')\n",
    "    print(\"Copying faces...\")\n",
    "    i = 0\n",
    "    for file in files:\n",
    "        copyfile('./train_images_test/1/' + file, './02big/1/' + file)\n",
    "        i += 1\n",
    "        if(i%10000 == 0): print(\"copied: \" + str(i))\n",
    "    print(\"Copying done!\")\n",
    "\n",
    "\n",
    "def mitteln():\n",
    "    print(\"Mitteln\")\n",
    "    newpath = \"03medium\"\n",
    "    if not os.path.exists(newpath):\n",
    "        os.makedirs(newpath)\n",
    "    newpath = \"03medium/0\"\n",
    "    if not os.path.exists(newpath):\n",
    "        os.makedirs(newpath)\n",
    "    newpath = \"03medium/1\"\n",
    "    if not os.path.exists(newpath):\n",
    "        os.makedirs(newpath)\n",
    "\n",
    "    #0nofaces\n",
    "    print(\"duplicating nofaces\")\n",
    "    duplicate(45860)\n",
    "    to_move = os.listdir('./duplicated/')\n",
    "    i = 0\n",
    "    for file in to_move:\n",
    "        copyfile('./duplicated/' + file, './03medium/0/' + file)\n",
    "        os.remove('./duplicated/' + file)\n",
    "        i += 1\n",
    "        if(i%10000 == 0): print(\"copied: \" + str(i))\n",
    "    \n",
    "    #1faces\n",
    "    print(\"choosing faces\")\n",
    "    choice(45860)\n",
    "    to_move = os.listdir('./ausgewaehlt/')\n",
    "    i = 0\n",
    "    print(\"start copying\")\n",
    "    for file in to_move:\n",
    "        copyfile('./ausgewaehlt/' + file, './03medium/1/' + file)\n",
    "        os.remove('./ausgewaehlt/' + file)\n",
    "        i += 1\n",
    "        if(i%10000 == 0): print(\"copied: \" + str(i))\n",
    "\n",
    "\n",
    "start_date = time.time()\n",
    "print(\"Start time: \" + str(time.strftime(\"%d.%m.%Y %H:%M:%S\")))\n",
    "\n",
    "#auswahl()\n",
    "#hochrechnen()\n",
    "mitteln()\n",
    "\n",
    "newpath = \"ausgewaehlt\"\n",
    "if os.path.exists(newpath):\n",
    "    os.remove(newpath)\n",
    "newpath = \"duplicated\"\n",
    "if os.path.exists(newpath):\n",
    "    os.remove(newpath)\n",
    "\n",
    "end_date = time.time()\n",
    "dauer = end_date - start_date\n",
    "print(\"Fertig! Gesamte Dauer: \" + str(dauer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nclass Net(nn.Module):\\n    def __init__(self):\\n        super(Net, self).__init__()\\n        self.conv1 = nn.Conv2d(1, 6, 5)\\n        self.pool = nn.MaxPool2d(2, 2)\\n        self.conv2 = nn.Conv2d(6, 16, 5)\\n        self.fc1 = nn.Linear(16 * 6 * 6, 32)\\n        self.fc2 = nn.Linear(32, 16)\\n        self.fc3 = nn.Linear(16, 2)\\n    def forward(self, x):\\n        x = self.pool(F.relu(self.conv1(x)))\\n        x = self.pool(F.relu(self.conv2(x)))\\n        x = x.view(-1, 16 * 6 * 6)\\n        x = F.relu(self.fc1(x))\\n        x = F.relu(self.fc2(x))\\n        x = self.fc3(x)\\n        return x\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NET\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.conv3 = nn.Conv2d(16, 32, 5)\n",
    "        self.fc1 = nn.Linear(32, 64)\n",
    "        self.fc2 = nn.Linear(64, 16)\n",
    "        self.fc3 = nn.Linear(16, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        y = x\n",
    "        test = self.feature_numeration(x)\n",
    "        x = x.view(-1, 32)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "    def feature_numeration(self, x):\n",
    "        size = x.size()[1:]\n",
    "        count = 1\n",
    "        for i in size:\n",
    "            count = count + i\n",
    "        return count\n",
    "\"\"\"\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 6 * 6, 32)\n",
    "        self.fc2 = nn.Linear(32, 16)\n",
    "        self.fc3 = nn.Linear(16, 2)\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 6 * 6)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "Testing\n",
      "Accuracy of the network on the 10000 test images: 89 %\n",
      "[1,   200] loss: 0.694\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-b9a271e0cb16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0mvarEnum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0mtest_after_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;31m# get the inputs; data is a list of [inputs, labels]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \"\"\"\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m255\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteStorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetbands\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#LOAD DATA\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from net import Net\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "\n",
    "def test_after_epoch(index):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for dataTest in test_loader:\n",
    "            imagesTest, labelsTest = dataTest\n",
    "            outputsTest = net(imagesTest)\n",
    "            _, predicted = torch.max(outputsTest.data, 1)\n",
    "            total += labelsTest.size(0)\n",
    "            correct += (predicted == labelsTest).sum().item()\n",
    "    print(\"Testing\")\n",
    "    overfit_index.append(index)\n",
    "    overfit_array.append(100 * correct / total)\n",
    "    print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "            100 * correct / total))\n",
    "\n",
    "train_dir = './03medium'\n",
    "test_dir = './test_images'\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.Grayscale(),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize(mean=(0,),std=(1,))])\n",
    "\n",
    "train_data = torchvision.datasets.ImageFolder(train_dir, transform=transform)\n",
    "test_data = torchvision.datasets.ImageFolder(test_dir, transform=transform)\n",
    "\n",
    "valid_size = 0.2\n",
    "batch_size = 32\n",
    "\n",
    "num_train = len(train_data)\n",
    "indices_train = list(range(num_train))\n",
    "np.random.shuffle(indices_train)\n",
    "split_tv = int(np.floor(valid_size * num_train))\n",
    "train_new_idx, valid_idx = indices_train[split_tv:],indices_train[:split_tv]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_new_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=train_sampler)\n",
    "valid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=valid_sampler)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "classes = ('noface','face')\n",
    "net = Net()\n",
    "\n",
    "# for epoch in range(1, n_epochs+1):\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\"\"\", weight_decay=0.0001\"\"\"\n",
    "\n",
    "#Visual variables\n",
    "loss_array = []\n",
    "loss_indicator = []\n",
    "step = 0\n",
    "epoch_array = []\n",
    "epoch_indicator = []\n",
    "epoch_index = 1\n",
    "epoch_indicator.append(0)\n",
    "epoch_array.append(1)\n",
    "overfit_index = []\n",
    "overfit_array = []\n",
    "epoch_count = 0\n",
    "\n",
    "for epoch in range(30):  # loop over the dataset multiple times\n",
    "    print(\"epoch: \" + str(epoch))\n",
    "    running_loss = 0.0\n",
    "    varEnum = enumerate(train_loader)\n",
    "    if epoch > 0:\n",
    "        test_after_epoch(epoch)\n",
    "    for i, data in enumerate(train_loader):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 200 == 199:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 200))\n",
    "            step += 200\n",
    "            loss_array.append(running_loss/200)\n",
    "            loss_indicator.append(step)\n",
    "            running_loss = 0.0\n",
    "    epoch_indicator.append(step)\n",
    "    epoch_array.append(epoch_index)\n",
    "    epoch_index += 1\n",
    "\n",
    "\n",
    "print('Finished Training')\n",
    "# for data, target in train_loader:\n",
    "\n",
    "\"\"\"\n",
    "test_loss = 0.0\n",
    "count = 0\n",
    "for i, data in enumerate(test_loader):\n",
    "    inputs, labels = data\n",
    "    outputs = net(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    count = i\n",
    "    test_loss = loss.item\n",
    "avg_loss = test_loss / count\n",
    "\"\"\"\n",
    "\n",
    "with open('overfitting_data.txt', 'a') as writeTo:\n",
    "    writeTo.write(\"\\n\\n\")\n",
    "    writeTo.write(str(overfit_index))\n",
    "    writeTo.write(\"\\n\")\n",
    "    writeTo.write((str(overfit_array)))\n",
    "\n",
    "fig, loss_plot = plt.subplots()\n",
    "loss_plot.plot( loss_indicator,loss_array, color =\"red\", label = \"Loss function\")\n",
    "loss_plot.set_xlabel(\"Batches processed\")\n",
    "loss_plot.set_ylabel(\"Average loss function\")\n",
    "\n",
    "epoch_plot = loss_plot.twinx()\n",
    "epoch_plot.step( epoch_indicator, epoch_array, color = \"gray\", label = \"Epoch\")\n",
    "epoch_plot.set_ylabel(\"Epoch #\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "fig.savefig('Loss function_epoch plot.jpg',\n",
    "            format='jpeg',\n",
    "            dpi=100,\n",
    "            bbox_inches='tight')\n",
    "\n",
    "fig2 = plt.figure(2)\n",
    "plt.title(\"Overfitting curve\")\n",
    "plt.plot(overfit_index, overfit_array)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.show()\n",
    "# save the plot as a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PYRAMID\n",
    "\n",
    "import torch\n",
    "import cv2\n",
    "\n",
    "def pyramid(image, scale=1.5, minSize=(30, 30)):\n",
    "    # yield the original image\n",
    "    yield image\n",
    "    # keep looping over the pyramid\n",
    "    while True:\n",
    "        # compute the new dimensions of the image and resize it\n",
    "        w = int(image.shape[0] / scale)\n",
    "        h = int(image.shape[1] / scale)\n",
    "        #image = imutils.resize(image, width=w)\n",
    "        image = cv2.resize(image, (h,w))\n",
    "        \n",
    "        # if the resized image does not meet the supplied minimum\n",
    "        # size, then stop constructing the pyramid\n",
    "        if image.shape[0] < minSize[1] or image.shape[1] < minSize[0]:\n",
    "            break\n",
    "        # yield the next image in the pyramid\n",
    "        yield image\n",
    "\n",
    "def sliding_window(image, stepSize, windowSize):\n",
    "    # slide a window across the image\n",
    "    for y in range(0, image.shape[0], stepSize):\n",
    "        for x in range(0, image.shape[1], stepSize):\n",
    "            # yield the current window\n",
    "            yield (x, y, image[y:y + windowSize[1], x:x + windowSize[0]])\n",
    "\n",
    "\n",
    "def pyramid_sliding_window_detection(net, image, scale, winW, winH, stepSize):\n",
    "    # Store the initial image before resize, it will be used for the final printing\n",
    "    faces_img = image.copy()\n",
    "   \n",
    "    # loop over the image pyramid\n",
    "    # all_detected_faces : contains for each pyramid level the scaling factor and the detected faces corresponding to\n",
    "    # pyramid level\n",
    "    all_detected_faces = []\n",
    "    for resized in pyramid(image, scale=scale):\n",
    "        detected_faces = []\n",
    "        curr_scale_factor = image.shape[0] / resized.shape[0]\n",
    "        # loop over the sliding window for each layer of the pyramid\n",
    "        for (x, y, window) in sliding_window(resized, stepSize=stepSize, windowSize=(winW, winH)):\n",
    "            # if the window does not meet our desired window size, ignore it\n",
    "            if window.shape[0] != winH or window.shape[1] != winW:\n",
    "                continue\n",
    "            # We use the 36*36 window to match the net's img input size\n",
    "            resized_tensor = torch.from_numpy(window)\n",
    "            # Transform the 500*500 (2d) img to a 4d tensor (the additional 2 dimensions contain no information)\n",
    "            resized_tensor = resized_tensor[None, None, :, :]  # tensor shape is now [1,1,500,500]\n",
    "            # Feed the network the input tensor\n",
    "            output = net(resized_tensor)\n",
    "\n",
    "            # We only register faces with a prob higher than 0.99 to avoid false positives\n",
    "            # (softmax dim parameter : dim=0->rows add up to 1, dim=1->rows add up to 1)\n",
    "            softmax = torch.nn.functional.softmax(output, dim=1)\n",
    "            if softmax[0][1] >= 0.9:\n",
    "                detected_faces.append((x, y, float(softmax[0][1])))\n",
    "\n",
    "\n",
    "        #Add the detected faces and the corresponding factors to the all_faces variable\n",
    "        all_detected_faces.append([curr_scale_factor,detected_faces])\n",
    "  \n",
    "\n",
    "    # We use the non_max_supp algorithm to delete overlaping bounding boxes\n",
    "    # to avoid detecting the same face multiple times\n",
    "    for j in range(len(all_detected_faces)):\n",
    "        for i in range(len(all_detected_faces[j][1])): #all_detected_faces[j][1]->detected faces of the i-pyramid-level\n",
    "            # in this line we both :\n",
    "            # - change the tuple from a 2d (startX, startY) to a 4d (startX, startY, endX, endY)\n",
    "            # - multiply each number of the tuple by the current scale factor\n",
    "            #if(not i ==0):\n",
    "            prob = (all_detected_faces[j][1][i][2])\n",
    "            all_detected_faces[j][1][i] = (\n",
    "                                              all_detected_faces[j][1][i][0] * all_detected_faces[j][0], all_detected_faces[j][1][i][1] * all_detected_faces[j][0]\n",
    "                                          ) + (\n",
    "                                            (all_detected_faces[j][1][i][0] + winW)*all_detected_faces[j][0], (all_detected_faces[j][1][i][1] + winH)*all_detected_faces[j][0]\n",
    "            )\n",
    "            #if(not i==0):\n",
    "            tup = (all_detected_faces[j][1][i][0], all_detected_faces[j][1][i][1],all_detected_faces[j][1][i][2], all_detected_faces[j][1][i][3], prob)\n",
    "            all_detected_faces[j][1][i] = tup\n",
    "    #print(all_detected_faces)\n",
    "    # Concatenate detected faces into the same array\n",
    "    final_detected_faces = all_detected_faces\n",
    "    return final_detected_faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DRAW RECS\n",
    "from PIL import Image, ImageFont, ImageDraw, ImageEnhance\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Takes an address of an image, a destination address, and a list of rectangles\n",
    "#List of rectangles as follows: [[x,y,width,height],...]\n",
    "#Plots the rectangles into the images and saves it\n",
    "def drawrec_mult(image_src, image_dest, rect_list):\n",
    "    source_img = Image.open(image_src).convert(\"RGB\")\n",
    "    draw = ImageDraw.Draw(source_img)\n",
    "    for rect in rect_list:\n",
    "        x = rect[0]\n",
    "        y = rect[1]\n",
    "        size_x = rect[2]\n",
    "        size_y = rect[3]\n",
    "        draw.rectangle(((x, y), (x+size_x, y+size_y)), outline = \"red\")\n",
    "    out_file = \"output_test.jpeg\"\n",
    "    source_img.save(out_file, \"JPEG\")\n",
    "\n",
    "#Takes an address of an image, a destination address, and a list of rectangles\n",
    "#List of rectangles as follows: [[x,y,width,height,linewidth],...]\n",
    "#Plots the rectangles into the images and saves it\n",
    "def drawrec_mult_lw(image_src, image_dest, rect_list):\n",
    "    image_array = mpimg.imread(image_src)\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    for rect in rect_list:\n",
    "        x = rect[0]\n",
    "        y = rect[1]\n",
    "        size_x = rect[2]\n",
    "        size_y = rect[3]\n",
    "        width = rect[4]\n",
    "        rect = plt.Rectangle((x, y), size_x, size_y, fill=False, edgecolor = 'red',linewidth=width)\n",
    "        ax.add_patch(rect)\n",
    "        plt.imshow(image_array)\n",
    "    fig.savefig(image_dest)\n",
    "\n",
    "#Takes an address of an image, a destination address, and proportions of a rectangle\n",
    "#Plots the rectangles into the images and saves it\n",
    "def drawrec(image_src, x, y, size_x, size_y):\n",
    "\n",
    "    source_img = Image.open(image_src).convert(\"RGB\")\n",
    "    draw = ImageDraw.Draw(source_img)\n",
    "    draw.rectangle(((x, y), (x+size_x, y+size_y)), outline = \"red\")\n",
    "    out_file = \"output_test.jpeg\"\n",
    "    source_img.save(out_file, \"JPEG\")\n",
    "\n",
    "#Takes an address of an image, a destination address, and proportions of a rectangle plus a linewidth\n",
    "#Plots the rectangles into the images and saves it\n",
    "def drawrec_lw(image_src, image_dest, x, y, size_x, size_y, linewidth):\n",
    "    image_array = mpimg.imread(image_src)\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    rect = plt.Rectangle((x, y), size_x, size_y, fill=False, edgecolor = 'red',linewidth=linewidth)\n",
    "    ax.add_patch(rect)\n",
    "    plt.imshow(image_array) # Bildarray\n",
    "    #plt.show()\n",
    "    fig.savefig(image_dest)\n",
    "\n",
    "#Example (Bild1.png is some image in folder):\n",
    "#entry1 = [1,1,100,100,3]\n",
    "#entry2 = [200,200,20,40,2]\n",
    "#list_rec = [entry1,entry2]\n",
    "#drawrec_mult_lw(\"Bild1.png\", \"output_test.jpeg\", list_rec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "[1,   200] loss: 0.690\n",
      "[1,   400] loss: 0.690\n",
      "[1,   600] loss: 0.689\n",
      "[1,   800] loss: 0.690\n",
      "[1,  1000] loss: 0.689\n",
      "[1,  1200] loss: 0.688\n",
      "[1,  1400] loss: 0.687\n",
      "[1,  1600] loss: 0.689\n",
      "[1,  1800] loss: 0.686\n",
      "[1,  2000] loss: 0.685\n",
      "[1,  2200] loss: 0.681\n",
      "[1,  2400] loss: 0.671\n",
      "[1,  2600] loss: 0.632\n",
      "epoch: 1\n",
      "[2,   200] loss: 0.320\n",
      "[2,   400] loss: 0.273\n",
      "[2,   600] loss: 0.229\n",
      "[2,   800] loss: 0.192\n",
      "[2,  1000] loss: 0.197\n",
      "[2,  1200] loss: 0.180\n",
      "[2,  1400] loss: 0.151\n",
      "[2,  1600] loss: 0.164\n",
      "[2,  1800] loss: 0.153\n",
      "[2,  2000] loss: 0.136\n",
      "[2,  2200] loss: 0.140\n",
      "[2,  2400] loss: 0.140\n",
      "[2,  2600] loss: 0.124\n",
      "epoch: 2\n",
      "[3,   200] loss: 0.115\n",
      "[3,   400] loss: 0.117\n",
      "[3,   600] loss: 0.107\n",
      "[3,   800] loss: 0.100\n",
      "[3,  1000] loss: 0.104\n",
      "[3,  1200] loss: 0.103\n",
      "[3,  1400] loss: 0.102\n",
      "[3,  1600] loss: 0.105\n",
      "[3,  1800] loss: 0.098\n",
      "[3,  2000] loss: 0.090\n",
      "[3,  2200] loss: 0.078\n",
      "[3,  2400] loss: 0.072\n",
      "[3,  2600] loss: 0.069\n",
      "epoch: 3\n",
      "[4,   200] loss: 0.076\n",
      "[4,   400] loss: 0.071\n",
      "[4,   600] loss: 0.066\n",
      "[4,   800] loss: 0.068\n",
      "[4,  1000] loss: 0.061\n",
      "[4,  1200] loss: 0.066\n",
      "[4,  1400] loss: 0.073\n",
      "[4,  1600] loss: 0.057\n",
      "[4,  1800] loss: 0.065\n",
      "[4,  2000] loss: 0.064\n",
      "[4,  2200] loss: 0.049\n",
      "[4,  2400] loss: 0.058\n",
      "[4,  2600] loss: 0.049\n",
      "epoch: 4\n",
      "[5,   200] loss: 0.060\n",
      "[5,   400] loss: 0.052\n",
      "[5,   600] loss: 0.055\n",
      "[5,   800] loss: 0.049\n",
      "[5,  1000] loss: 0.052\n",
      "[5,  1200] loss: 0.047\n",
      "[5,  1400] loss: 0.042\n",
      "[5,  1600] loss: 0.052\n",
      "[5,  1800] loss: 0.041\n",
      "[5,  2000] loss: 0.035\n",
      "[5,  2200] loss: 0.042\n",
      "[5,  2400] loss: 0.039\n",
      "[5,  2600] loss: 0.043\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "import load_data\n",
    "net = load_data.net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NMS\n",
    "import numpy as np\n",
    "\n",
    "def nms(dets, thresh):\n",
    "    \n",
    "    x1 = dets[:, 0]\n",
    "    y1 = dets[:, 1]\n",
    "    x2 = dets[:, 2]\n",
    "    y2 = dets[:, 3]\n",
    "    scores = dets[:, 4]\n",
    "\n",
    "    areas = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    order = scores.argsort()[::-1]\n",
    "\n",
    "    keep = []\n",
    "    while order.size > 0:\n",
    "        i = order[0]\n",
    "        keep.append(i)\n",
    "        xx1 = np.maximum(x1[i], x1[order[1:]])\n",
    "        yy1 = np.maximum(y1[i], y1[order[1:]])\n",
    "        xx2 = np.minimum(x2[i], x2[order[1:]])\n",
    "        yy2 = np.minimum(y2[i], y2[order[1:]])\n",
    "\n",
    "        w = np.maximum(0.0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0.0, yy2 - yy1 + 1)\n",
    "        inter = w * h\n",
    "        ovr = inter / (areas[i] + areas[order[1:]] - inter)\n",
    "        i = 0\n",
    "        nn = 0\n",
    "        for entry in inter:\n",
    "            if(entry == 0.0):\n",
    "                i += 1\n",
    "            else: nn += 1\n",
    "        print(str(i) + \" times zero overlap; \" + str(nn) + \" times overlap detected.\")\n",
    "        inds = np.where(ovr <= thresh)[0]\n",
    "        order = order[inds + 1]\n",
    "\n",
    "    return keep\n",
    "\n",
    "\n",
    "# Malisiewicz et al.\n",
    "def non_max_suppression_fast(boxes, overlapThresh):\n",
    "\t# if there are no boxes, return an empty list\n",
    "\tif len(boxes) == 0:\n",
    "\t\treturn []\n",
    "\t# if the bounding boxes integers, convert them to floats --\n",
    "\t# this is important since we'll be doing a bunch of divisions\n",
    "\tif boxes.dtype.kind == \"i\":\n",
    "\t\tboxes = boxes.astype(\"float\")\n",
    "\t# initialize the list of picked indexes\t\n",
    "\tpick = []\n",
    "\t# grab the coordinates of the bounding boxes\n",
    "\tx1 = boxes[:,0]\n",
    "\ty1 = boxes[:,1]\n",
    "\tx2 = boxes[:,2]\n",
    "\ty2 = boxes[:,3]\n",
    "\t# compute the area of the bounding boxes and sort the bounding\n",
    "\t# boxes by the bottom-right y-coordinate of the bounding box\n",
    "\tarea = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "\tidxs = np.argsort(y2)\n",
    "\t# keep looping while some indexes still remain in the indexes\n",
    "\t# list\n",
    "\twhile len(idxs) > 0:\n",
    "        # grab the last index in the indexes list and add the\n",
    "\t\t# index value to the list of picked indexes\n",
    "\t\tlast = len(idxs) - 1\n",
    "\t\ti = idxs[last]\n",
    "\t\tpick.append(i)\n",
    "\t\t# find the largest (x, y) coordinates for the start of\n",
    "\t\t# the bounding box and the smallest (x, y) coordinates\n",
    "\t\t# for the end of the bounding box\n",
    "\t\txx1 = np.maximum(x1[i], x1[idxs[:last]])\n",
    "\t\tyy1 = np.maximum(y1[i], y1[idxs[:last]])\n",
    "\t\txx2 = np.minimum(x2[i], x2[idxs[:last]])\n",
    "\t\tyy2 = np.minimum(y2[i], y2[idxs[:last]])\n",
    "\t\t# compute the width and height of the bounding box\n",
    "\t\tw = np.maximum(0, xx2 - xx1 + 1)\n",
    "\t\th = np.maximum(0, yy2 - yy1 + 1)\n",
    "\t\t# compute the ratio of overlap\n",
    "\t\toverlap = (w * h) / area[idxs[:last]]\n",
    "\t\t# delete all indexes from the index list that have\n",
    "\t\tidxs = np.delete(idxs, np.concatenate(([last],\n",
    "\t\t\tnp.where(overlap > overlapThresh)[0])))\n",
    "\t# return only the bounding boxes that were picked using the\n",
    "\t# integer data type\n",
    "\treturn pick\n",
    "\n",
    "\n",
    "def nms_bboxes(bboxes):\n",
    "    arr_boxes = []\n",
    "    for scale in bboxes:\n",
    "        array = bboxes[1]\n",
    "        for element in scale[1]:\n",
    "            toAdd = [[element[0], element[1], element[2], element[3], element[4]]]\n",
    "            arr_boxes += toAdd\n",
    "            #arr_boxes.append(to_app)\n",
    "    arr_boxes_2 = np.array(arr_boxes)\n",
    "    if (len(arr_boxes_2) == 0):\n",
    "        print(\"No faces found!\")\n",
    "        return ([],[])\n",
    "    result = nms(arr_boxes_2, 0.5)\n",
    "    return (arr_boxes,result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RECOGNIZE FACES\n",
    "import numpy as np\n",
    "import cv2\n",
    "import drawrecs\n",
    "import nms\n",
    "from pyramid import pyramid_sliding_window_detection\n",
    "import load_data\n",
    "\n",
    "net = load_data.net\n",
    "#with open('trainednetwork.txt', 'a') as writeTo:\n",
    "#    writeTo.write(str(net))\n",
    "\n",
    "\n",
    "print(\"load test image\")\n",
    "\n",
    "image_for_tracking = \"./testbild2.jpg\"\n",
    "\n",
    "test_img = cv2.imread(image_for_tracking)\n",
    "gray = cv2.cvtColor(test_img, cv2.COLOR_BGR2GRAY).astype(float)\n",
    "gray = gray/128.0 - 1.0\n",
    "\n",
    "print(\"building bboxes\")\n",
    "\n",
    "bboxes2 = pyramid_sliding_window_detection(net,np.array(gray, dtype='float32'), 1.2, 36, 36, 5)\n",
    "\n",
    "#import bboxes\n",
    "#bboxes2 = bboxes.bboxes1\n",
    "\n",
    "\n",
    "#Zum Testen kann bboxes als txt file gespeichert werden, um von da weiter zu arbeiten, ohne das Netzwerk immer neu aufbauen zu müssen\n",
    "with open('bboxes.txt', 'a') as writeTo:\n",
    "    writeTo.write(str(bboxes2))\n",
    "print(\"bboxed built!\")\n",
    "\n",
    "arr_boxes, keep = nms.nms_bboxes(bboxes2)\n",
    "print(\"nms sorted from \" + str(len(arr_boxes)) + \" to \" + str(len(keep)))\n",
    "testrecs = []\n",
    "\n",
    "for scale in bboxes2:\n",
    "    # Fürs Testen kann man bestimmte Rechteckgrößen bbevorzugen\n",
    "    #i += 1\n",
    "    #if (i<10): continue\n",
    "    for element in scale[1]:\n",
    "        #if len(element) == 4:\n",
    "        toAdd = [element[0], element[1], element[2]-element[0], element[3]-element[1]]\n",
    "        testrecs += [toAdd]\n",
    "\n",
    "\n",
    "to_draw = []\n",
    "for to_keep in keep:\n",
    "    to_draw += [arr_boxes[to_keep]]\n",
    "\n",
    "\n",
    "drawrecs.drawrec_mult(image_for_tracking, \"testout.jpg\", to_draw)\n",
    "drawrecs.drawrec_mult(image_for_tracking, \"testout_mit_allen.jpg\", testrecs)\n",
    "\n",
    "print(\"Image drawn. Exciting!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
