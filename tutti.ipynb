{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time: 14.10.2021 10:05:23\n",
      "Mitteln\n",
      "duplicating nofaces\n",
      "to_dup: 26950\n",
      "duplicated: 10000\n",
      "duplicated: 20000\n",
      "to_dup: 18910\n",
      "duplicated: 30000\n",
      "duplicated: 40000\n",
      "copied: 10000\n",
      "copied: 20000\n",
      "copied: 30000\n",
      "copied: 40000\n",
      "choosing faces\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "done choosing\n",
      "start copying\n",
      "copied: 10000\n",
      "copied: 20000\n",
      "copied: 30000\n",
      "copied: 40000\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 1] Operation not permitted: 'ausgewaehlt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-693c9319afee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0mnewpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"ausgewaehlt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0mnewpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"duplicated\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 1] Operation not permitted: 'ausgewaehlt'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from shutil import copyfile\n",
    "import time\n",
    "\n",
    "from random import sample\n",
    "\n",
    "def choice(desired):\n",
    "    files = os.listdir('./train_images_test/1/')\n",
    "    i = 0\n",
    "    for file in sample(files,desired):\n",
    "        #os.remove('/train_images_test/1/'+ file)\n",
    "        newpath = \"ausgewaehlt\"\n",
    "        if not os.path.exists(newpath):\n",
    "            os.makedirs(newpath)\n",
    "        copyfile('./train_images_test/1/' + file, './ausgewaehlt/' + file)\n",
    "        if(i%10000 == 0):\n",
    "            print(i)\n",
    "        i += 1\n",
    "    print(\"done choosing\")\n",
    "\n",
    "def duplicate(desired):\n",
    "    aktuell = 0\n",
    "    files = os.listdir('./train_images_test/0/')\n",
    "    i = aktuell\n",
    "    loop = 0\n",
    "    newpath = \"duplicated\"\n",
    "    if not os.path.exists(newpath):\n",
    "        os.makedirs(newpath)\n",
    "    while (aktuell < desired):\n",
    "        if((desired - aktuell) < aktuell): to_dup = desired - aktuell\n",
    "        else: to_dup = 26950\n",
    "        print(\"to_dup: \" + str(to_dup))\n",
    "        for file in sample(files, to_dup):\n",
    "            copyfile('./train_images_test/0/' + file, './duplicated/' + str(loop) + file)\n",
    "            i += 1\n",
    "            if(i%10000 == 0): print(\"duplicated: \" + str(i))\n",
    "        aktuell += to_dup\n",
    "        loop += 1\n",
    "\n",
    "def auswahl():\n",
    "    newpath = \"01small\"\n",
    "    if not os.path.exists(newpath):\n",
    "        os.makedirs(newpath)\n",
    "    newpath = \"01small/0\"\n",
    "    if not os.path.exists(newpath):\n",
    "        os.makedirs(newpath)\n",
    "    newpath = \"01small/1\"\n",
    "    if not os.path.exists(newpath):\n",
    "        os.makedirs(newpath)\n",
    "\n",
    "    #0_nofaces\n",
    "    files = os.listdir('./train_images_test/0/')\n",
    "    print(\"Copying no faces...\")\n",
    "    for file in files:\n",
    "        copyfile('./train_images_test/0/' + file, './01small/0/' + file)\n",
    "    print(\"Copying done!\")\n",
    "\n",
    "    #1_faces\n",
    "    files = os.listdir('./train_images_test/1/')\n",
    "    choice(26950)\n",
    "    to_move = os.listdir('./ausgewaehlt/')\n",
    "    print('copying files to destination')\n",
    "    i = 0\n",
    "    for file in to_move:\n",
    "        copyfile('./ausgewaehlt/' + file, './01small/1/' + file)\n",
    "        os.remove('./ausgewaehlt/' + file)\n",
    "        i += 1\n",
    "        if(i%10000 == 0): print(\"copied: \" + str(i))\n",
    "\n",
    "\n",
    "def hochrechnen():\n",
    "    print(\"Hochrechnen....\")\n",
    "    newpath = \"02big\"\n",
    "    if not os.path.exists(newpath):\n",
    "        os.makedirs(newpath)\n",
    "    newpath = \"02big/0\"\n",
    "    if not os.path.exists(newpath):\n",
    "        os.makedirs(newpath)\n",
    "    newpath = \"02big/1\"\n",
    "    if not os.path.exists(newpath):\n",
    "        os.makedirs(newpath)\n",
    "\n",
    "    #0nofaces\n",
    "    print(\"duplicating nofaces\")\n",
    "    duplicate(64770)\n",
    "    to_move = os.listdir('./duplicated/')\n",
    "    print(\"Copying files\")\n",
    "    for file in to_move:\n",
    "        copyfile('./duplicated/' + file, './02big/0/' + file)\n",
    "        os.remove(\"./duplicated/\" + file)\n",
    "    \n",
    "    #1faces\n",
    "    print(\"choosing faces\")\n",
    "    files = os.listdir('./train_images_test/1/')\n",
    "    print(\"Copying faces...\")\n",
    "    i = 0\n",
    "    for file in files:\n",
    "        copyfile('./train_images_test/1/' + file, './02big/1/' + file)\n",
    "        i += 1\n",
    "        if(i%10000 == 0): print(\"copied: \" + str(i))\n",
    "    print(\"Copying done!\")\n",
    "\n",
    "\n",
    "def mitteln():\n",
    "    print(\"Mitteln\")\n",
    "    newpath = \"03medium\"\n",
    "    if not os.path.exists(newpath):\n",
    "        os.makedirs(newpath)\n",
    "    newpath = \"03medium/0\"\n",
    "    if not os.path.exists(newpath):\n",
    "        os.makedirs(newpath)\n",
    "    newpath = \"03medium/1\"\n",
    "    if not os.path.exists(newpath):\n",
    "        os.makedirs(newpath)\n",
    "\n",
    "    #0nofaces\n",
    "    print(\"duplicating nofaces\")\n",
    "    duplicate(45860)\n",
    "    to_move = os.listdir('./duplicated/')\n",
    "    i = 0\n",
    "    for file in to_move:\n",
    "        copyfile('./duplicated/' + file, './03medium/0/' + file)\n",
    "        os.remove('./duplicated/' + file)\n",
    "        i += 1\n",
    "        if(i%10000 == 0): print(\"copied: \" + str(i))\n",
    "    \n",
    "    #1faces\n",
    "    print(\"choosing faces\")\n",
    "    choice(45860)\n",
    "    to_move = os.listdir('./ausgewaehlt/')\n",
    "    i = 0\n",
    "    print(\"start copying\")\n",
    "    for file in to_move:\n",
    "        copyfile('./ausgewaehlt/' + file, './03medium/1/' + file)\n",
    "        os.remove('./ausgewaehlt/' + file)\n",
    "        i += 1\n",
    "        if(i%10000 == 0): print(\"copied: \" + str(i))\n",
    "\n",
    "\n",
    "start_date = time.time()\n",
    "print(\"Start time: \" + str(time.strftime(\"%d.%m.%Y %H:%M:%S\")))\n",
    "\n",
    "#auswahl()\n",
    "#hochrechnen()\n",
    "mitteln()\n",
    "\n",
    "newpath = \"ausgewaehlt\"\n",
    "if os.path.exists(newpath):\n",
    "    os.remove(newpath)\n",
    "newpath = \"duplicated\"\n",
    "if os.path.exists(newpath):\n",
    "    os.remove(newpath)\n",
    "\n",
    "end_date = time.time()\n",
    "dauer = end_date - start_date\n",
    "print(\"Fertig! Gesamte Dauer: \" + str(dauer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 6 * 6, 32)\n",
    "        self.fc2 = nn.Linear(32, 16)\n",
    "        self.fc3 = nn.Linear(16, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 6 * 6)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "[1,   200] loss: 0.700\n",
      "[1,   400] loss: 0.689\n",
      "[1,   600] loss: 0.686\n",
      "[1,   800] loss: 0.684\n",
      "[1,  1000] loss: 0.677\n",
      "[1,  1200] loss: 0.658\n",
      "[1,  1400] loss: 0.545\n",
      "[1,  1600] loss: 0.347\n",
      "[1,  1800] loss: 0.285\n",
      "[1,  2000] loss: 0.236\n",
      "[1,  2200] loss: 0.224\n",
      "[1,  2400] loss: 0.194\n",
      "[1,  2600] loss: 0.184\n",
      "epoch: 1\n",
      "[2,   200] loss: 0.158\n",
      "[2,   400] loss: 0.163\n",
      "[2,   600] loss: 0.149\n",
      "[2,   800] loss: 0.143\n",
      "[2,  1000] loss: 0.136\n",
      "[2,  1200] loss: 0.136\n",
      "[2,  1400] loss: 0.122\n",
      "[2,  1600] loss: 0.107\n",
      "[2,  1800] loss: 0.104\n",
      "[2,  2000] loss: 0.111\n",
      "[2,  2200] loss: 0.103\n",
      "[2,  2400] loss: 0.103\n",
      "[2,  2600] loss: 0.094\n",
      "epoch: 2\n",
      "[3,   200] loss: 0.090\n",
      "[3,   400] loss: 0.082\n",
      "[3,   600] loss: 0.094\n",
      "[3,   800] loss: 0.092\n",
      "[3,  1000] loss: 0.072\n",
      "[3,  1200] loss: 0.071\n",
      "[3,  1400] loss: 0.074\n",
      "[3,  1600] loss: 0.073\n",
      "[3,  1800] loss: 0.078\n",
      "[3,  2000] loss: 0.071\n",
      "[3,  2200] loss: 0.069\n",
      "[3,  2400] loss: 0.076\n",
      "[3,  2600] loss: 0.061\n",
      "epoch: 3\n",
      "[4,   200] loss: 0.062\n",
      "[4,   400] loss: 0.055\n",
      "[4,   600] loss: 0.047\n",
      "[4,   800] loss: 0.064\n",
      "[4,  1000] loss: 0.061\n",
      "[4,  1200] loss: 0.054\n",
      "[4,  1400] loss: 0.057\n",
      "[4,  1600] loss: 0.067\n",
      "[4,  1800] loss: 0.051\n",
      "[4,  2000] loss: 0.057\n",
      "[4,  2200] loss: 0.053\n",
      "[4,  2400] loss: 0.052\n",
      "[4,  2600] loss: 0.048\n",
      "epoch: 4\n",
      "[5,   200] loss: 0.046\n",
      "[5,   400] loss: 0.044\n",
      "[5,   600] loss: 0.055\n",
      "[5,   800] loss: 0.048\n",
      "[5,  1000] loss: 0.043\n",
      "[5,  1200] loss: 0.049\n",
      "[5,  1400] loss: 0.047\n",
      "[5,  1600] loss: 0.046\n",
      "[5,  1800] loss: 0.033\n",
      "[5,  2000] loss: 0.045\n",
      "[5,  2200] loss: 0.037\n",
      "[5,  2400] loss: 0.037\n",
      "[5,  2600] loss: 0.043\n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nplt.title(\"Loss function by iteration\")\\nplt.xlabel(\"step\")\\nplt.ylabel(\"Average loss\")\\nplt.plot( loss_indicator,loss_array, color =\"red\")\\nplt.show()\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from net import Net\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "train_dir = './03medium'\n",
    "test_dir = './test_images'\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.Grayscale(),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize(mean=(0,),std=(1,))])\n",
    "\n",
    "train_data = torchvision.datasets.ImageFolder(train_dir, transform=transform)\n",
    "test_data = torchvision.datasets.ImageFolder(test_dir, transform=transform)\n",
    "\n",
    "valid_size = 0.2\n",
    "batch_size = 32\n",
    "\n",
    "num_train = len(train_data)\n",
    "indices_train = list(range(num_train))\n",
    "np.random.shuffle(indices_train)\n",
    "split_tv = int(np.floor(valid_size * num_train))\n",
    "train_new_idx, valid_idx = indices_train[split_tv:],indices_train[:split_tv]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_new_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=train_sampler)\n",
    "valid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=valid_sampler)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "classes = ('noface','face')\n",
    "net = Net()\n",
    "\n",
    "# for epoch in range(1, n_epochs+1):\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "#Visual variables\n",
    "loss_array = []\n",
    "loss_indicator = []\n",
    "step = 0\n",
    "\n",
    "for epoch in range(5):  # loop over the dataset multiple times\n",
    "    print(\"epoch: \" + str(epoch))\n",
    "    running_loss = 0.0\n",
    "    varEnum = enumerate(train_loader)\n",
    "\n",
    "    for i, data in enumerate(train_loader):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 200 == 199:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 200))\n",
    "            step += 200\n",
    "            loss_array.append(running_loss/200)\n",
    "            loss_indicator.append(step)\n",
    "            running_loss = 0.0\n",
    "\n",
    "\n",
    "print('Finished Training')\n",
    "# for data, target in train_loader:\n",
    "\n",
    "\"\"\"\n",
    "test_loss = 0.0\n",
    "count = 0\n",
    "for i, data in enumerate(test_loader):\n",
    "    inputs, labels = data\n",
    "    outputs = net(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    count = i\n",
    "    test_loss = loss.item\n",
    "avg_loss = test_loss / count\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "plt.title(\"Loss function by iteration\")\n",
    "plt.xlabel(\"step\")\n",
    "plt.ylabel(\"Average loss\")\n",
    "plt.plot( loss_indicator,loss_array, color =\"red\")\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "\n",
    "def pyramid(image, scale=1.5, minSize=(30, 30)):\n",
    "    # yield the original image\n",
    "    yield image\n",
    "    # keep looping over the pyramid\n",
    "    while True:\n",
    "        # compute the new dimensions of the image and resize it\n",
    "        w = int(image.shape[0] / scale)\n",
    "        h = int(image.shape[1] / scale)\n",
    "        #image = imutils.resize(image, width=w)\n",
    "        image = cv2.resize(image, (h,w))\n",
    "        \n",
    "        # if the resized image does not meet the supplied minimum\n",
    "        # size, then stop constructing the pyramid\n",
    "        if image.shape[0] < minSize[1] or image.shape[1] < minSize[0]:\n",
    "            break\n",
    "        # yield the next image in the pyramid\n",
    "        yield image\n",
    "\n",
    "def sliding_window(image, stepSize, windowSize):\n",
    "    # slide a window across the image\n",
    "    for y in range(0, image.shape[0], stepSize):\n",
    "        for x in range(0, image.shape[1], stepSize):\n",
    "            # yield the current window\n",
    "            yield (x, y, image[y:y + windowSize[1], x:x + windowSize[0]])\n",
    "\n",
    "\n",
    "def pyramid_sliding_window_detection(net, image, scale, winW, winH, stepSize):\n",
    "    # Store the initial image before resize, it will be used for the final printing\n",
    "    faces_img = image.copy()\n",
    "   \n",
    "    # loop over the image pyramid\n",
    "    # all_detected_faces : contains for each pyramid level the scaling factor and the detected faces corresponding to\n",
    "    # pyramid level\n",
    "    all_detected_faces = []\n",
    "    for resized in pyramid(image, scale=scale):\n",
    "        detected_faces = []\n",
    "        curr_scale_factor = image.shape[0] / resized.shape[0]\n",
    "        # loop over the sliding window for each layer of the pyramid\n",
    "        for (x, y, window) in sliding_window(resized, stepSize=stepSize, windowSize=(winW, winH)):\n",
    "            # if the window does not meet our desired window size, ignore it\n",
    "            if window.shape[0] != winH or window.shape[1] != winW:\n",
    "                continue\n",
    "            # We use the 36*36 window to match the net's img input size\n",
    "            resized_tensor = torch.from_numpy(window)\n",
    "            # Transform the 500*500 (2d) img to a 4d tensor (the additional 2 dimensions contain no information)\n",
    "            resized_tensor = resized_tensor[None, None, :, :]  # tensor shape is now [1,1,500,500]\n",
    "            # Feed the network the input tensor\n",
    "            output = net(resized_tensor)\n",
    "\n",
    "            # We only register faces with a prob higher than 0.99 to avoid false positives\n",
    "            # (softmax dim parameter : dim=0->rows add up to 1, dim=1->rows add up to 1)\n",
    "            softmax = torch.nn.functional.softmax(output, dim=1)\n",
    "            if softmax[0][1] >= 0.9:\n",
    "                detected_faces.append((x, y))\n",
    "\n",
    "\n",
    "        #Add the detected faces and the corresponding factors to the all_faces variable\n",
    "        all_detected_faces.append([curr_scale_factor,detected_faces])\n",
    "  \n",
    "\n",
    "    # We use the non_max_supp algorithm to delete overlaping bounding boxes\n",
    "    # to avoid detecting the same face multiple times\n",
    "    for j in range(len(all_detected_faces)):\n",
    "        for i in range(len(all_detected_faces[j][1])): #all_detected_faces[j][1]->detected faces of the i-pyramid-level\n",
    "            # in this line we both :\n",
    "            # - change the tuple from a 2d (startX, startY) to a 4d (startX, startY, endX, endY)\n",
    "            # - multiply each number of the tuple by the current scale factor\n",
    "            all_detected_faces[j][1][i] = (\n",
    "                                              all_detected_faces[j][1][i][0] * all_detected_faces[j][0], all_detected_faces[j][1][i][1] * all_detected_faces[j][0]\n",
    "                                          ) + (\n",
    "                                            (all_detected_faces[j][1][i][0] + winW)*all_detected_faces[j][0], (all_detected_faces[j][1][i][1] + winH)*all_detected_faces[j][0]\n",
    "            )\n",
    "    #print(all_detected_faces)\n",
    "    # Concatenate detected faces into the same array\n",
    "    final_detected_faces = all_detected_faces\n",
    "    return final_detected_faces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageFont, ImageDraw, ImageEnhance\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Takes an address of an image, a destination address, and a list of rectangles\n",
    "#List of rectangles as follows: [[x,y,width,height],...]\n",
    "#Plots the rectangles into the images and saves it\n",
    "def drawrec_mult(image_src, image_dest, rect_list):\n",
    "    source_img = Image.open(image_src).convert(\"RGB\")\n",
    "    draw = ImageDraw.Draw(source_img)\n",
    "    for rect in rect_list:\n",
    "        x = rect[0]\n",
    "        y = rect[1]\n",
    "        size_x = rect[2]\n",
    "        size_y = rect[3]\n",
    "        draw.rectangle(((x, y), (x+size_x, y+size_y)), outline = \"red\")\n",
    "    out_file = \"output_test.jpeg\"\n",
    "    source_img.save(out_file, \"JPEG\")\n",
    "\n",
    "#Takes an address of an image, a destination address, and a list of rectangles\n",
    "#List of rectangles as follows: [[x,y,width,height,linewidth],...]\n",
    "#Plots the rectangles into the images and saves it\n",
    "def drawrec_mult_lw(image_src, image_dest, rect_list):\n",
    "    image_array = mpimg.imread(image_src)\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    for rect in rect_list:\n",
    "        x = rect[0]\n",
    "        y = rect[1]\n",
    "        size_x = rect[2]\n",
    "        size_y = rect[3]\n",
    "        width = rect[4]\n",
    "        rect = plt.Rectangle((x, y), size_x, size_y, fill=False, edgecolor = 'red',linewidth=width)\n",
    "        ax.add_patch(rect)\n",
    "        plt.imshow(image_array)\n",
    "    fig.savefig(image_dest)\n",
    "\n",
    "#Takes an address of an image, a destination address, and proportions of a rectangle\n",
    "#Plots the rectangles into the images and saves it\n",
    "def drawrec(image_src, x, y, size_x, size_y):\n",
    "\n",
    "    source_img = Image.open(image_src).convert(\"RGB\")\n",
    "    draw = ImageDraw.Draw(source_img)\n",
    "    draw.rectangle(((x, y), (x+size_x, y+size_y)), outline = \"red\")\n",
    "    out_file = \"output_test.jpeg\"\n",
    "    source_img.save(out_file, \"JPEG\")\n",
    "\n",
    "#Takes an address of an image, a destination address, and proportions of a rectangle plus a linewidth\n",
    "#Plots the rectangles into the images and saves it\n",
    "def drawrec_lw(image_src, image_dest, x, y, size_x, size_y, linewidth):\n",
    "    image_array = mpimg.imread(image_src)\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    rect = plt.Rectangle((x, y), size_x, size_y, fill=False, edgecolor = 'red',linewidth=linewidth)\n",
    "    ax.add_patch(rect)\n",
    "    plt.imshow(image_array) # Bildarray\n",
    "    #plt.show()\n",
    "    fig.savefig(image_dest)\n",
    "\n",
    "#Example (Bild1.png is some image in folder):\n",
    "#entry1 = [1,1,100,100,3]\n",
    "#entry2 = [200,200,20,40,2]\n",
    "#list_rec = [entry1,entry2]\n",
    "#drawrec_mult_lw(\"Bild1.png\", \"output_test.jpeg\", list_rec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "[1,   200] loss: 0.690\n",
      "[1,   400] loss: 0.690\n",
      "[1,   600] loss: 0.689\n",
      "[1,   800] loss: 0.690\n",
      "[1,  1000] loss: 0.689\n",
      "[1,  1200] loss: 0.688\n",
      "[1,  1400] loss: 0.687\n",
      "[1,  1600] loss: 0.689\n",
      "[1,  1800] loss: 0.686\n",
      "[1,  2000] loss: 0.685\n",
      "[1,  2200] loss: 0.681\n",
      "[1,  2400] loss: 0.671\n",
      "[1,  2600] loss: 0.632\n",
      "epoch: 1\n",
      "[2,   200] loss: 0.320\n",
      "[2,   400] loss: 0.273\n",
      "[2,   600] loss: 0.229\n",
      "[2,   800] loss: 0.192\n",
      "[2,  1000] loss: 0.197\n",
      "[2,  1200] loss: 0.180\n",
      "[2,  1400] loss: 0.151\n",
      "[2,  1600] loss: 0.164\n",
      "[2,  1800] loss: 0.153\n",
      "[2,  2000] loss: 0.136\n",
      "[2,  2200] loss: 0.140\n",
      "[2,  2400] loss: 0.140\n",
      "[2,  2600] loss: 0.124\n",
      "epoch: 2\n",
      "[3,   200] loss: 0.115\n",
      "[3,   400] loss: 0.117\n",
      "[3,   600] loss: 0.107\n",
      "[3,   800] loss: 0.100\n",
      "[3,  1000] loss: 0.104\n",
      "[3,  1200] loss: 0.103\n",
      "[3,  1400] loss: 0.102\n",
      "[3,  1600] loss: 0.105\n",
      "[3,  1800] loss: 0.098\n",
      "[3,  2000] loss: 0.090\n",
      "[3,  2200] loss: 0.078\n",
      "[3,  2400] loss: 0.072\n",
      "[3,  2600] loss: 0.069\n",
      "epoch: 3\n",
      "[4,   200] loss: 0.076\n",
      "[4,   400] loss: 0.071\n",
      "[4,   600] loss: 0.066\n",
      "[4,   800] loss: 0.068\n",
      "[4,  1000] loss: 0.061\n",
      "[4,  1200] loss: 0.066\n",
      "[4,  1400] loss: 0.073\n",
      "[4,  1600] loss: 0.057\n",
      "[4,  1800] loss: 0.065\n",
      "[4,  2000] loss: 0.064\n",
      "[4,  2200] loss: 0.049\n",
      "[4,  2400] loss: 0.058\n",
      "[4,  2600] loss: 0.049\n",
      "epoch: 4\n",
      "[5,   200] loss: 0.060\n",
      "[5,   400] loss: 0.052\n",
      "[5,   600] loss: 0.055\n",
      "[5,   800] loss: 0.049\n",
      "[5,  1000] loss: 0.052\n",
      "[5,  1200] loss: 0.047\n",
      "[5,  1400] loss: 0.042\n",
      "[5,  1600] loss: 0.052\n",
      "[5,  1800] loss: 0.041\n",
      "[5,  2000] loss: 0.035\n",
      "[5,  2200] loss: 0.042\n",
      "[5,  2400] loss: 0.039\n",
      "[5,  2600] loss: 0.043\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "import load_data\n",
    "net = load_data.net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load test image\n",
      "building bboxes\n",
      "bboxed built!\n",
      "Image drawn. Exiting.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import drawrecs\n",
    "from pyramid import pyramid_sliding_window_detection\n",
    "\n",
    "\n",
    "print(\"load test image\")\n",
    "\n",
    "test_img = cv2.imread(\"./img.jpg\")\n",
    "gray = cv2.cvtColor(test_img, cv2.COLOR_BGR2GRAY).astype(float)\n",
    "gray = gray/128.0 - 1.0\n",
    "\n",
    "print(\"building bboxes\")\n",
    "\n",
    "bboxes = pyramid_sliding_window_detection(net,np.array(gray, dtype='float32'), 1.2, 36, 36, 5)\n",
    "\n",
    "#Zum Testen kann bboxes als txt file gespeichert werden, um von da weiter zu arbeiten, ohne das Netzwerk immer neu aufbauen zu müssen\n",
    "#with open('bboxes.txt', 'a') as writeTo:\n",
    "#    writeTo.write(str(bboxes))\n",
    "print(\"bboxed built!\")\n",
    "\n",
    "#i = 0\n",
    "rectangles = []\n",
    "for scale in bboxes:\n",
    "    # Fürs Testen kann man bestimmte Rechteckgrößen bbevorzugen\n",
    "    #i += 1\n",
    "    #if (i<10): continue\n",
    "    for element in scale[1]:\n",
    "        if len(element) == 4:\n",
    "            toAdd = [element[0], element[1], element[2]-element[0], element[3]-element[1]]\n",
    "            rectangles += [toAdd]\n",
    "\n",
    "#print(rectangles)\n",
    "\n",
    "drawrecs.drawrec_mult(\"img.jpg\", \"testout.jpg\", rectangles)\n",
    "\n",
    "print(\"Image drawn. Exiting.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 91 %\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import load_data\n",
    "\n",
    "correct = 0\n",
    "trainedNet = load_data.net\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in load_data.test_loader:\n",
    "        images, labels = data\n",
    "        outputs = trainedNet(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Malisiewicz et al.\n",
    "def non_max_suppression_fast(boxes, overlapThresh):\n",
    "    # if there are no boxes, return an empty list\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "    # if the bounding boxes integers, convert them to floats --\n",
    "    # this is important since we'll be doing a bunch of divisions\n",
    "    if boxes.dtype.kind == \"i\":\n",
    "        boxes = boxes.astype(\"float\")\n",
    "    # initialize the list of picked indexes\t\n",
    "    pick = []\n",
    "    # grab the coordinates of the bounding boxes\n",
    "    x1 = boxes[:,0]\n",
    "    y1 = boxes[:,1]\n",
    "    x2 = boxes[:,2]\n",
    "    y2 = boxes[:,3]\n",
    "    # compute the area of the bounding boxes and sort the bounding\n",
    "    # boxes by the bottom-right y-coordinate of the bounding box\n",
    "    area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    idxs = np.argsort(y2)\n",
    "    # keep looping while some indexes still remain in the indexes\n",
    "    # list\n",
    "    while len(idxs) > 0:\n",
    "        # grab the last index in the indexes list and add the\n",
    "        # index value to the list of picked indexes\n",
    "        last = len(idxs) - 1\n",
    "        i = idxs[last]\n",
    "        pick.append(i)\n",
    "        # find the largest (x, y) coordinates for the start of\n",
    "        # the bounding box and the smallest (x, y) coordinates\n",
    "        # for the end of the bounding box\n",
    "        xx1 = np.maximum(x1[i], x1[idxs[:last]])\n",
    "        yy1 = np.maximum(y1[i], y1[idxs[:last]])\n",
    "        xx2 = np.minimum(x2[i], x2[idxs[:last]])\n",
    "        yy2 = np.minimum(y2[i], y2[idxs[:last]])\n",
    "        # compute the width and height of the bounding box\n",
    "        w = np.maximum(0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0, yy2 - yy1 + 1)\n",
    "        # compute the ratio of overlap\n",
    "        overlap = (w * h) / area[idxs[:last]]\n",
    "        # delete all indexes from the index list that have\n",
    "        idxs = np.delete(idxs, np.concatenate(([last],\n",
    "            np.where(overlap > overlapThresh)[0])))\n",
    "    # return only the bounding boxes that were picked using the\n",
    "    # integer data type\n",
    "    return boxes[pick].astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# Fast R-CNN\n",
    "# Copyright (c) 2015 Microsoft\n",
    "# Licensed under The MIT License [see LICENSE for details]\n",
    "# Written by Ross Girshick\n",
    "# --------------------------------------------------------\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def nms(dets, thresh):\n",
    "    x1 = dets[:, 0]\n",
    "    y1 = dets[:, 1]\n",
    "    x2 = dets[:, 2]\n",
    "    y2 = dets[:, 3]\n",
    "    scores = dets[:, 4]\n",
    "\n",
    "    areas = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    order = scores.argsort()[::-1]\n",
    "\n",
    "    keep = []\n",
    "    while order.size > 0:\n",
    "        i = order[0]\n",
    "        keep.append(i)\n",
    "        xx1 = np.maximum(x1[i], x1[order[1:]])\n",
    "        yy1 = np.maximum(y1[i], y1[order[1:]])\n",
    "        xx2 = np.minimum(x2[i], x2[order[1:]])\n",
    "        yy2 = np.minimum(y2[i], y2[order[1:]])\n",
    "\n",
    "        w = np.maximum(0.0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0.0, yy2 - yy1 + 1)\n",
    "        inter = w * h\n",
    "        ovr = inter / (areas[i] + areas[order[1:]] - inter)\n",
    "\n",
    "        inds = np.where(ovr <= thresh)[0]\n",
    "        order = order[inds + 1]\n",
    "\n",
    "    return keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-03a3553e9ae7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-3026aea80263>\u001b[0m in \u001b[0;36mnms\u001b[0;34m(dets, thresh)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0my1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "nms(bboxes, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(bboxes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
